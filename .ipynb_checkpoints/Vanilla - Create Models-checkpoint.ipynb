{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Visualization - Create Models\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Current Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "os.chdir(current_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Training / Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X data (features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Y data (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Convert y_train and y_test to categorical datatypes\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Construct Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Setup Create New Model Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_new_model(input_dim=784, hidden_dim=512, dropout_rate=0.2, summary=True, dropout=True):\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1 - INPUT\n",
    "    model.add(Dense(hidden_dim, activation='relu', input_shape=(input_dim,)))\n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Layer 2 - HIDDEN\n",
    "    model.add(Dense(hidden_dim, activation='relu'))\n",
    "    if dropout:\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Layer 3 - OUTPUT\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    if summary: print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Generate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706.0\n",
      "Trainable params: 669,706.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 200)               157000    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 199,210.0\n",
      "Trainable params: 199,210.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 89,610.0\n",
      "Trainable params: 89,610.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "new_model_num = 3\n",
    "hidden_dims = [512, 200, 100]\n",
    "models = {}\n",
    "\n",
    "for model_num in range(1, new_model_num+1):\n",
    "    new_model_name = \"model_{}\".format(model_num)\n",
    "    hidden_dim = hidden_dims[model_num-1]\n",
    "    new_model = create_new_model(hidden_dim=hidden_dim)\n",
    "    models[new_model_name] = {\"model_t0\" : new_model}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Setup Train Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_model(model):\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    model_score = {\"test loss\" : test_score[0], \n",
    "                        \"test accuracy\" : test_score[1],\n",
    "                        \"train accuracy\" : train_score[1]\n",
    "                  }\n",
    "    \n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_steps = 15\n",
    "num_training_samples = 10000\n",
    "num_test_samples = 1000\n",
    "\n",
    "    \n",
    "for model_name, items in models.items():\n",
    "    \n",
    "    # Set current model\n",
    "    model = items[\"model_t0\"]\n",
    "    \n",
    "    # Get layer 1 weights from initiale model\n",
    "    layer_1_initial_weights = np.array(model.layers[0].get_weights()[0]).flatten()\n",
    "        \n",
    "    # Declare time series list to store layer 1 weights at each epoch step\n",
    "    model_weights_time_series = [layer_1_initial_weights.tolist()]\n",
    "    \n",
    "    # Get initial model scores\n",
    "    initial_model_score = score_model(model)\n",
    "    model_scores_time_series = [initial_model_score]\n",
    "    \n",
    "    # Increment by 1 epoch each loop, store weight from layer 1 of each iteration of the model\n",
    "    for time_step in range(1, time_steps+1):\n",
    "        \n",
    "        # Randomly draw *num_training_samples* from x_test, y_test\n",
    "        random_training_indices = [np.random.randint(0, 60000) for _ in range(num_training_samples)]\n",
    "        random_test_indices = [np.random.randint(0, 10000) for _ in range(num_test_samples)]\n",
    "        \n",
    "        # Set stubbed training / testing data\n",
    "        x_train_stubb = x_train[random_training_indices]\n",
    "        y_train_stubb = y_train[random_training_indices]\n",
    "        x_test_stubb = x_test[random_test_indices]\n",
    "        y_test_stubb = y_test[random_test_indices]\n",
    "        \n",
    "        # Set verbosity\n",
    "        verbosity = 1 if time_steps < 10 else 0\n",
    "        \n",
    "        # Fit the model\n",
    "        model.fit(x_train_stubb, y_train_stubb, epochs=1, batch_size=batch_size, validation_data=(x_test_stubb, y_test_stubb), verbose=verbosity)\n",
    "        \n",
    "        # Get the layer 1 weights\n",
    "        layer_1_weights = np.array(model.layers[0].get_weights()[0]).flatten()\n",
    "       \n",
    "        # Store layer 1 weights\n",
    "        model_weights_time_series.append(layer_1_weights.tolist())\n",
    "        \n",
    "        \n",
    "        # Get model score and store it\n",
    "        model_score = score_model(model)\n",
    "        model_scores_time_series.append(model_score)\n",
    "    \n",
    "    # Store model weights time sequence\n",
    "    models[model_name][\"epochs\"] = model_weights_time_series\n",
    "    \n",
    "    # Store final model\n",
    "    models[model_name][\"model_tf\"] = model\n",
    "    \n",
    "    # Store model scores at each epoch\n",
    "    models[model_name][\"scores\"] = model_scores_time_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the weight distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_number = 10\n",
    "\n",
    "# Setup figure\n",
    "fig = plt.figure()\n",
    "\n",
    "for model_name, items in models.items():\n",
    "    for time_step, layer in enumerate(items[\"epochs\"]):\n",
    "        \n",
    "        if time_step >= plot_number:\n",
    "            break\n",
    "        \n",
    "        # Setup the axis\n",
    "        ax = fig.add_subplot(plot_number, 1, time_step+1)\n",
    "        \n",
    "        # Plot the layer weights\n",
    "        sns.distplot(layer, bins='auto', kde=False, rug=False, ax=ax, color=\"#99ff99\", hist_kws=dict(alpha=0.75))\n",
    "        \n",
    "    # Figure attributes\n",
    "    fig.subplots_adjust(hspace=0.8)\n",
    "    fig.set_figheight(30)\n",
    "    fig.set_figwidth(15)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Score Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for model_name, items in models.items():\n",
    "    print(model_name)\n",
    "    model = items[\"model_tf\"]\n",
    "    test_score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    train_score = model.evaluate(x_train, y_train, verbose=0)\n",
    "    models[model_name][\"score_tf\"] = {\"test loss\" : test_score[0], \n",
    "                                   \"test accuracy\" : test_score[1],\n",
    "                                   \"train accuracy\" : train_score[1]}\n",
    "    \n",
    "    print('Test loss: {}'.format(test_score[0]))\n",
    "    \n",
    "    print('Train accuracy: {}'.format(train_score[1]))\n",
    "    print('Test accuracy: {}'.format(test_score[1]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Weight Matrices from Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weights to json function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weights_to_json(data, file_name):\n",
    "    # Set file path\n",
    "    file_path = \"json_files/{}.json\".format(file_name)\n",
    "    \n",
    "    # Dump json data\n",
    "    json.dump(data, codecs.open(file_path, 'w', encoding='utf-8'), separators=(',', ':'), sort_keys=True, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format and write data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, items in models.items():\n",
    "    \n",
    "    # Define the edata to write\n",
    "    write_data = { \"epochs\" : items[\"epochs\"],\n",
    "                   \"scores\" : items[\"scores\"] \n",
    "                 }\n",
    "    \n",
    "    # write to json\n",
    "    weights_to_json(write_data, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write list of models in csv for D3 to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"json_files/model_list.csv\", \"w\") as outfile:\n",
    "    outfile.write(\"Model Name,Model Filename\\n\")\n",
    "    for model_key in models.keys():\n",
    "        outfile.write(model_key)\n",
    "        outfile.write(\",\")\n",
    "        outfile.write(model_key+\".json\")\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Trained Model and Weights to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model_name, items in models.items():\n",
    "\n",
    "    # Set model\n",
    "    model = items[\"model_tf\"]\n",
    "\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "\n",
    "    # Write model to file\n",
    "    outfile_name = \"models/{}.json\".format(model_name)\n",
    "    with open(outfile_name, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    # Serialize weights to HDF5 and save\n",
    "    model.save_weights(\"models/{}_weights.h5\".format(model_name))\n",
    "\n",
    "    print(\"Saved {} to disk.\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "- https://keras.io/getting-started/sequential-model-guide/\n",
    "- https://keras.io/models/sequential/#sequential-model-methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy and Images\n",
    "- http://scikit-image.org/docs/dev/user_guide/numpy_images.html\n",
    "- astropy, but useful: http://prancer.physics.louisville.edu/astrowiki/index.php/Image_processing_with_Python_and_SciPy\n",
    "- https://www.safaribooksonline.com/library/view/programming-computer-vision/9781449341916/ch01.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizing images for NN processing\n",
    "- https://datascience.stackexchange.com/questions/5224/how-to-prepare-images-for-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database\n",
    "- MongoDB: https://realpython.com/blog/python/introduction-to-mongodb-and-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Net One Step at a Time\n",
    "- https://github.com/fchollet/keras/issues/85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dict to JSON\n",
    "- http://robotfantastic.org/serializing-python-data-to-json-some-edge-cases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Size Explained Well\n",
    "- https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MIT Places\n",
    "The compressed file of resized 256*256 images, containing train set and validation set of Places 205.\n",
    "http://data.csail.mit.edu/places/places205/imagesPlaces205_resize.tar.gz"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
